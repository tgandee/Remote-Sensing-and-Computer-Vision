{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Video Stabilization\n",
        "Note: This code is from [SergejVolkov / video_smoothing](https://github.com/SergejVolkov/video_smoothing). All credit for the code itself goes to the authors of this repository. In this notebook, we provide explanatory detail to the  algorithms provided."
      ],
      "metadata": {
        "id": "4i-bQoRboYA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG-so0QqeLoQ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import numpy.linalg as lin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best homography that is closest to the current homography model\n",
        "def get_sub(prev_warp: list, current_warp: np.array, max_n: int) -> tuple:\n",
        "    best_dist = float(\"+inf\")\n",
        "    best_warp_ind = -1\n",
        "    target_warp = lin.inv(current_warp)\n",
        "    for i in range(len(prev_warp)):\n",
        "        new_dist = lin.norm(np.dot(prev_warp[max_n // 2], lin.inv(prev_warp[i])) - target_warp)\n",
        "        if new_dist < best_dist:\n",
        "            best_dist = new_dist\n",
        "            best_warp_ind = i\n",
        "    sub_warp = None\n",
        "    if best_warp_ind != -1:\n",
        "        sub_warp = np.dot(prev_warp[max_n // 2], lin.inv(prev_warp[best_warp_ind]))\n",
        "    return best_warp_ind - max_n // 2, sub_warp"
      ],
      "metadata": {
        "id": "CxSiyvxxoVye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_trajectory(cap: cv2.VideoCapture, amount: int) -> tuple:\n",
        "    max_n = amount\n",
        "    # List of homographies, starting with the initial frame (identity matrix)\n",
        "    n_shift = [np.identity(3)]\n",
        "    apply_warp = []\n",
        "    prev_frame = None\n",
        "    curr_ind = 0\n",
        "    sub_layers = [(0, None)]\n",
        "\n",
        "    # For each frame\n",
        "    while True:\n",
        "        ret, frame_color = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame_color, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Extract points to track\n",
        "        prev_pts = cv2.goodFeaturesToTrack(frame, maxCorners=200,\n",
        "                                           qualityLevel=0.01, minDistance=30,\n",
        "                                           blockSize=3)\n",
        "        if prev_frame is not None:\n",
        "\n",
        "            # From https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\n",
        "            # \"Computes a dense optical flow using the Gunnar Farneback's algorithm.\"\n",
        "            # Calculate optical flow (i.e. track feature points)\n",
        "            curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_frame, frame,\n",
        "                                                             prev_pts, None)\n",
        "            \n",
        "            # Find homography based on matched features using RANSAC algorithm\n",
        "            M, _ = cv2.findHomography(prev_pts, curr_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "            # Local: Homography from previous frame to current frame\n",
        "            # Global: Homography from first frame to current frame\n",
        "\n",
        "            # Push the incoming LOCAL homography to list\n",
        "            n_shift.append(np.dot(M, n_shift[-1]))\n",
        "\n",
        "            # If there are over max_n homographies, allow a shift for one frame\n",
        "            # \"Shifting\" means we disregard the first homography in our list.\n",
        "            # If we shift multiple times, we will diverge from the first frame's\n",
        "            # initial camera coordinates.\n",
        "            if len(n_shift) > max_n:\n",
        "                n_shift.pop(0)\n",
        "                inv = lin.inv(n_shift[0])\n",
        "                for i in range(len(n_shift)):\n",
        "                    n_shift[i] = np.dot(n_shift[i], inv)\n",
        "            # We are done with the previous frame, assign the current frame to previous frame\n",
        "            prev_frame = frame\n",
        "\n",
        "            # If the current frame is at least the max_n-th frame\n",
        "            if curr_ind >= max_n:\n",
        "                # Allocate space by averaging the first half homography models\n",
        "                apply_warp.append(np.dot(np.average(np.array(n_shift), 0),\n",
        "                                         lin.inv(np.average(np.array(n_shift[max_n // 2 - 1: max_n // 2 + 1]), 0))))\n",
        "            elif curr_ind > max_n // 2:\n",
        "                # Average a few homographies\n",
        "                apply_warp.append(np.dot(np.average(np.array(n_shift), 0),\n",
        "                                         lin.inv(np.average(np.array(n_shift[curr_ind - max_n // 2 - 1: curr_ind - max_n // 2 + 1]), 0))))\n",
        "            elif curr_ind == max_n // 2:\n",
        "                # Average all homographies\n",
        "                apply_warp.append(np.average(np.array(n_shift), 0))\n",
        "\n",
        "            # If we added an averaged homography\n",
        "            if curr_ind > max_n // 2:\n",
        "                # Add sub-layer\n",
        "                sub_layers.append(get_sub(n_shift, apply_warp[-1], max_n))\n",
        "        else:\n",
        "            prev_frame = frame\n",
        "        curr_ind += 1\n",
        "\n",
        "    # For the first half of frames\n",
        "    for curr_ind in range(0, max_n // 2):\n",
        "        # Shift homographies to the left 1\n",
        "        inv = lin.inv(n_shift.pop(0))\n",
        "        for i in range(len(n_shift)):\n",
        "            n_shift[i] = np.dot(n_shift[i], inv)\n",
        "        # Only average the first half of homographies\n",
        "        if max_n // 2 < len(n_shift):\n",
        "            apply_warp.append(np.dot(np.average(np.array(n_shift), 0),\n",
        "                                     lin.inv(np.average(np.array(n_shift[max_n // 2 - 1: max_n // 2 + 1]), 0))))\n",
        "        else:\n",
        "            # else, average all homographies\n",
        "            apply_warp.append(np.average(np.array(n_shift), 0))\n",
        "    return apply_warp, sub_layers"
      ],
      "metadata": {
        "id": "hHqwOE5toT8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_cool(cap: cv2.VideoCapture, amount: int) -> tuple:\n",
        "\n",
        "    # List of homographies, starting with the initial frame (identity matrix)\n",
        "    n_shift = [np.identity(3)]\n",
        "    apply_warp = []\n",
        "    prev_frame = None\n",
        "    curr_ind = 0\n",
        "    sub_layers = [(0, None)]\n",
        "\n",
        "    # For each frame\n",
        "    while True:\n",
        "        ret, frame_color = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame_color, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Extract points to track\n",
        "        prev_pts = cv2.goodFeaturesToTrack(frame, maxCorners=200,\n",
        "                                           qualityLevel=0.01, minDistance=30,\n",
        "                                           blockSize=3)\n",
        "        if prev_frame is not None:\n",
        "\n",
        "            # From https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\n",
        "            # \"Computes a dense optical flow using the Gunnar Farneback's algorithm.\"\n",
        "            # Calculate optical flow (i.e. track feature points)\n",
        "            curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_frame, frame,\n",
        "                                                             prev_pts, None)\n",
        "            \n",
        "            # Find homography based on matched features using RANSAC algorithm\n",
        "            M, _ = cv2.findHomography(prev_pts, curr_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "            # Local: Homography from previous frame to current frame\n",
        "            # Global: Homography from first frame to current frame\n",
        "\n",
        "            # Push the incoming LOCAL homography to list\n",
        "            n_shift.append(np.dot(M, n_shift[-1]))\n",
        "\n",
        "            # If there are over \"amount\" homographies, allow a shift for one frame\n",
        "            # \"Shifting\" means we disregard the first homography in our list.\n",
        "            # If we shift multiple times, we will diverge from the first frame's\n",
        "            # initial camera coordinates.\n",
        "            if len(n_shift) > amount:\n",
        "                n_shift.pop(0)\n",
        "                inv = lin.inv(n_shift[0])\n",
        "                for i in range(len(n_shift)):\n",
        "                    n_shift[i] = np.dot(n_shift[i], inv)\n",
        "\n",
        "            # We are dome with the previous frame, assign the current frame to previous frame\n",
        "            prev_frame = frame\n",
        "\n",
        "            # If the current frame is at least the \"amount\"th frame\n",
        "            if curr_ind >= amount:\n",
        "                # Allocate space by averaging the first half homography models\n",
        "                apply_warp.append(np.dot(np.average(np.array(n_shift), 0),\n",
        "                                         lin.inv(n_shift[amount // 2])))\n",
        "            # Else if the current frame is at least the \"amount / 2\"th frame\n",
        "            elif curr_ind >= amount // 2:\n",
        "\n",
        "                # Average a few homographies\n",
        "                apply_warp.append(np.dot(np.average(np.array(n_shift), 0),\n",
        "                                         lin.inv(n_shift[curr_ind - amount // 2])))\n",
        "            # If we added an averaged homography\n",
        "            if curr_ind > amount // 2:\n",
        "                # Add sub-layer\n",
        "                sub_layers.append(get_sub(n_shift, apply_warp[-1], amount))\n",
        "        else:\n",
        "            prev_frame = frame\n",
        "        curr_ind += 1\n",
        "\n",
        "    # For the first half of frames\n",
        "    for curr_ind in range(0, amount // 2):\n",
        "        # Shift homographies to the left 1\n",
        "        n_shift.pop(0)\n",
        "        inv = lin.inv(n_shift[0])\n",
        "        for i in range(len(n_shift)):\n",
        "            n_shift[i] = np.dot(n_shift[i], inv)\n",
        "        if amount // 2 < len(n_shift):\n",
        "            # Only average the first half of homographies\n",
        "            apply_warp.append(np.dot(np.average(np.array(n_shift), 0),\n",
        "                                     lin.inv(n_shift[amount // 2])))\n",
        "        else:\n",
        "            # Average all\n",
        "            apply_warp.append(np.average(np.array(n_shift), 0))\n",
        "    return apply_warp, sub_layers"
      ],
      "metadata": {
        "id": "jkd9x-2AoR3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    cap: Video capture to be processed\n",
        "    amount: Distance threshold to skip stablization and shift current and future frames\n",
        "'''\n",
        "def stabilize(cap: cv2.VideoCapture, amount: int) -> None:\n",
        "\n",
        "    # amount - I don't know what this does\n",
        "    amount = amount - amount % 2\n",
        "\n",
        "    print(\"Processing data...\")\n",
        "\n",
        "    # Get homographies and sub layers\n",
        "    # apply_warp, sub_layers = smooth_cool(cap, amount)\n",
        "    apply_warp, sub_layers = smooth_trajectory(cap, amount)\n",
        "\n",
        "    print(\"Applying smoothing...\")\n",
        "\n",
        "    cap.set(2, 0)\n",
        "    frames = []\n",
        "\n",
        "    # Read all frames\n",
        "    while True:\n",
        "        ret, frame_color = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame_color)\n",
        "\n",
        "    # Define the codec for output video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "    # Get frames per second\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Width and height of input video\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Initialize output video\n",
        "    out = cv2.VideoWriter('output.mp4', fourcc, fps, (w, h))\n",
        "\n",
        "    print(\"Writing to disk...\")\n",
        "\n",
        "    # For each frame\n",
        "    for curr_ind in range(len(frames)):\n",
        "\n",
        "        # Warp current frame with respective homography model\n",
        "        frame_color = cv2.warpPerspective(frames[curr_ind], apply_warp[curr_ind], (w, h))\n",
        "\n",
        "        # If a sub-layer does not exist for the current frame\n",
        "        if curr_ind < len(sub_layers) and sub_layers[curr_ind][1] is not None:\n",
        "            mask = cv2.warpPerspective(np.full(frame_color.shape, 255, dtype=np.uint8),\n",
        "                                       apply_warp[curr_ind], (w, h)) != 255\n",
        "            np.putmask(frame_color, mask,\n",
        "                       cv2.warpPerspective(frames[curr_ind + sub_layers[curr_ind][0]],\n",
        "                                           np.dot(apply_warp[curr_ind],\n",
        "                                                  sub_layers[curr_ind][1]), (w, h)))\n",
        "        out.write(frame_color)\n",
        "        #cv2.imshow('frame', frame_color)\n",
        "        #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        #    break\n",
        "\n",
        "    out.release()\n",
        "    print(\"Done\")"
      ],
      "metadata": {
        "id": "clERQ913oP6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(\"input.mp4\")\n",
        "# cap = cv2.VideoCapture(\"test2.MOD\")\n",
        "# cap = cv2.VideoCapture(\"test3.MOD\")\n",
        "# cap = cv2.VideoCapture(\"test4.MOD\")\n",
        "# cap = cv2.VideoCapture(\"test5.MOV\")\n",
        "\n",
        "stabilize(cap, 1000)\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lyd6Oh7bgGEK",
        "outputId": "7488fa6d-5329-42fa-e2ec-7f2756effd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data...\n",
            "Applying smoothing...\n",
            "Writing to disk...\n",
            "Done\n"
          ]
        }
      ]
    }
  ]
}